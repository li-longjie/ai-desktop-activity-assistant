#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªå®šä¹‰åµŒå…¥æ¨¡å— - é¿å…LangChainç‰ˆæœ¬å†²çª
ç›´æ¥ä½¿ç”¨SentenceTransformerå’ŒChromaDB
"""

import logging
import os
from typing import List, Dict, Any
import numpy as np
import time

# å…¨å±€å˜é‡
embeddings_model = None
chroma_client = None
collection = None

def init_embeddings():
    """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å’ŒChromaDB"""
    global embeddings_model, chroma_client, collection
    
    try:
        # 1. åˆå§‹åŒ–SentenceTransformer
        from sentence_transformers import SentenceTransformer
        logging.info("æ­£åœ¨åŠ è½½é˜¿é‡Œå·´å·´åµŒå…¥æ¨¡å‹...")
        embeddings_model = SentenceTransformer(
            'Alibaba-NLP/gte-multilingual-base', 
            trust_remote_code=True
        )
        logging.info("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # 2. åˆå§‹åŒ–ChromaDB
        import chromadb
        from chromadb.config import Settings
        
        # ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ•°æ®åº“è·¯å¾„
        try:
            from gui_config import gui_config
            CHROMA_DB_PATH = gui_config.get('paths.database_directory', 'chroma_db_activity')
        except ImportError:
            CHROMA_DB_PATH = "chroma_db_activity"

        chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        
        # åˆ›å»ºæˆ–è·å–é›†åˆ
        collection = chroma_client.get_or_create_collection(
            name="screen_activity",
            metadata={"description": "Screen activity embeddings"}
        )
        logging.info("âœ… ChromaDBåˆå§‹åŒ–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        logging.error(f"âŒ åµŒå…¥æ¨¡å‹æˆ–ChromaDBåˆå§‹åŒ–å¤±è´¥: {e}")
        embeddings_model = None
        chroma_client = None
        collection = None
        return False

def encode_text(text: str) -> List[float]:
    """ç¼–ç å•ä¸ªæ–‡æœ¬"""
    if embeddings_model is None:
        raise RuntimeError("åµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–")
    
    embedding = embeddings_model.encode(text, normalize_embeddings=True)
    return embedding.tolist()

def encode_texts(texts: List[str]) -> List[List[float]]:
    """ç¼–ç å¤šä¸ªæ–‡æœ¬"""
    if embeddings_model is None:
        raise RuntimeError("åµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–")
    
    embeddings = embeddings_model.encode(texts, normalize_embeddings=True)
    return embeddings.tolist()

def add_documents(documents: List[str], metadatas: List[Dict], ids: List[str]):
    """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰"""
    if collection is None:
        raise RuntimeError("ChromaDBé›†åˆæœªåˆå§‹åŒ–")
    
    # å‡å°æ‰¹æ¬¡å¤§å°ï¼Œæé«˜ç¨³å®šæ€§
    batch_size = 10  # æ¯æ‰¹å¤„ç†10ä¸ªæ–‡æ¡£ï¼ˆä»50å‡å°‘åˆ°10ï¼‰
    total_docs = len(documents)
    
    logging.info(f"å¼€å§‹åˆ†æ‰¹å¤„ç† {total_docs} ä¸ªæ–‡æ¡£ï¼Œæ¯æ‰¹ {batch_size} ä¸ª")
    
    success_count = 0
    
    for i in range(0, total_docs, batch_size):
        end_idx = min(i + batch_size, total_docs)
        batch_docs = documents[i:end_idx]
        batch_metas = metadatas[i:end_idx]
        batch_ids = ids[i:end_idx]
        
        batch_num = i//batch_size + 1
        total_batches = (total_docs-1)//batch_size + 1
        
        try:
            # ç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„åµŒå…¥
            logging.info(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_docs)} ä¸ªæ–‡æ¡£) - è¿›åº¦: {i}/{total_docs}")
            
            # é€ä¸ªå¤„ç†æ–‡æ¡£ä»¥é¿å…å†…å­˜é—®é¢˜
            batch_embeddings = []
            for j, doc in enumerate(batch_docs):
                try:
                    embedding = encode_text(doc)
                    batch_embeddings.append(embedding)
                    if j % 5 == 0:  # æ¯5ä¸ªæ–‡æ¡£æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        logging.info(f"   - å·²å¤„ç† {j+1}/{len(batch_docs)} ä¸ªæ–‡æ¡£")
                except Exception as e:
                    logging.error(f"âŒ å¤„ç†æ–‡æ¡£ {j+1} å¤±è´¥: {e}")
                    raise
            
            # æ·»åŠ åˆ°é›†åˆ
            logging.info(f"ğŸ“Š æ­£åœ¨å°†ç¬¬ {batch_num} æ‰¹æ•°æ®æ·»åŠ åˆ°æ•°æ®åº“...")
            collection.add(
                documents=batch_docs,
                metadatas=batch_metas,
                ids=batch_ids,
                embeddings=batch_embeddings
            )
            
            success_count += len(batch_docs)
            logging.info(f"âœ… ç¬¬ {batch_num}/{total_batches} æ‰¹å¤„ç†å®Œæˆ (ç´¯è®¡: {success_count}/{total_docs})")
            
            # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…èµ„æºç«äº‰
            time.sleep(0.1)
            
        except Exception as e:
            logging.error(f"âŒ ç¬¬ {batch_num} æ‰¹å¤„ç†å¤±è´¥: {e}")
            logging.info(f"ğŸ”„ å°è¯•é‡æ–°å¤„ç†ç¬¬ {batch_num} æ‰¹...")
            
            # å°è¯•é‡æ–°å¤„ç†ä¸€æ¬¡
            try:
                batch_embeddings = []
                for doc in batch_docs:
                    embedding = encode_text(doc)
                    batch_embeddings.append(embedding)
                
                collection.add(
                    documents=batch_docs,
                    metadatas=batch_metas,
                    ids=batch_ids,
                    embeddings=batch_embeddings
                )
                
                success_count += len(batch_docs)
                logging.info(f"âœ… ç¬¬ {batch_num} æ‰¹é‡è¯•æˆåŠŸ")
                
            except Exception as e2:
                logging.error(f"âŒ ç¬¬ {batch_num} æ‰¹é‡è¯•ä»ç„¶å¤±è´¥: {e2}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
                continue
    
    logging.info(f"ğŸ‰ æ‰¹å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{total_docs} ä¸ªæ–‡æ¡£")

def search_similar(query: str, k: int = 25, where_filter: Dict = None) -> List[Dict]:
    """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
    if collection is None:
        raise RuntimeError("ChromaDBé›†åˆæœªåˆå§‹åŒ–")
    
    # ç¼–ç æŸ¥è¯¢
    query_embedding = encode_text(query)
    
    # æ‰§è¡Œæœç´¢
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k,
        where=where_filter,
        include=['documents', 'metadatas', 'distances']
    )
    
    # æ ¼å¼åŒ–ç»“æœ
    formatted_results = []
    if results['documents'] and len(results['documents']) > 0:
        documents = results['documents'][0]
        metadatas = results['metadatas'][0] if results['metadatas'] else []
        distances = results['distances'][0] if results['distances'] else []
        
        for i, doc in enumerate(documents):
            result = {
                'page_content': doc,
                'metadata': metadatas[i] if i < len(metadatas) else {},
                'distance': distances[i] if i < len(distances) else 0.0
            }
            formatted_results.append(result)
    
    return formatted_results

def clear_collection():
    """æ¸…ç©ºé›†åˆ"""
    if collection is None:
        raise RuntimeError("ChromaDBé›†åˆæœªåˆå§‹åŒ–")
    
    # è·å–æ‰€æœ‰IDå¹¶åˆ é™¤
    existing_data = collection.get(include=[])
    if existing_data['ids']:
        collection.delete(ids=existing_data['ids'])
        logging.info(f"å·²æ¸…é™¤ {len(existing_data['ids'])} ä¸ªæ–‡æ¡£")

def get_collection_count() -> int:
    """è·å–é›†åˆä¸­çš„æ–‡æ¡£æ•°é‡"""
    if collection is None:
        return 0
    
    try:
        result = collection.count()
        return result
    except:
        return 0

def get_all_documents() -> List[Dict]:
    """è·å–é›†åˆä¸­çš„æ‰€æœ‰æ–‡æ¡£"""
    if collection is None:
        return []
    
    try:
        results = collection.get(include=['documents', 'metadatas'])
        documents = []
        
        if results['ids']:
            for i, doc_id in enumerate(results['ids']):
                doc = {
                    'id': doc_id,
                    'document': results['documents'][i] if i < len(results['documents']) else '',
                    'metadata': results['metadatas'][i] if i < len(results['metadatas']) else {}
                }
                documents.append(doc)
        
        return documents
    except Exception as e:
        logging.error(f"è·å–æ‰€æœ‰æ–‡æ¡£å¤±è´¥: {e}")
        return []

# å…¼å®¹æ€§åŒ…è£…å™¨ï¼Œæ¨¡æ‹ŸLangChainçš„æ¥å£
class CustomEmbeddings:
    """è‡ªå®šä¹‰åµŒå…¥ç±»ï¼Œå…¼å®¹åŸæœ‰æ¥å£"""
    
    def __init__(self):
        if not init_embeddings():
            raise RuntimeError("åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
    
    def embed_query(self, text: str) -> List[float]:
        """åµŒå…¥å•ä¸ªæŸ¥è¯¢"""
        return encode_text(text)
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """åµŒå…¥å¤šä¸ªæ–‡æ¡£"""
        return encode_texts(texts)

class CustomVectorStore:
    """è‡ªå®šä¹‰å‘é‡å­˜å‚¨ï¼Œå…¼å®¹åŸæœ‰æ¥å£"""
    
    def __init__(self):
        if collection is None:
            raise RuntimeError("ChromaDBæœªåˆå§‹åŒ–")
        self._collection = collection
    
    def similarity_search(self, query: str, k: int = 25, filter: Dict = None) -> List[Any]:
        """ç›¸ä¼¼æ€§æœç´¢"""
        results = search_similar(query, k=k, where_filter=filter)
        
        # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
        docs = []
        for result in results:
            doc = type('Document', (), {
                'page_content': result['page_content'],
                'metadata': result['metadata']
            })()
            docs.append(doc)
        
        return docs

# æµ‹è¯•å‡½æ•°
def test_custom_embeddings():
    """æµ‹è¯•è‡ªå®šä¹‰åµŒå…¥åŠŸèƒ½"""
    try:
        print("=== æµ‹è¯•è‡ªå®šä¹‰åµŒå…¥æ¨¡å— ===")
        
        # åˆå§‹åŒ–
        success = init_embeddings()
        if not success:
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return False
        
        print("âœ… åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç¼–ç 
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        embedding = encode_text(text)
        print(f"âœ… ç¼–ç æµ‹è¯•æˆåŠŸï¼Œç»´åº¦: {len(embedding)}")
        
        # æµ‹è¯•ChromaDB
        count = get_collection_count()
        print(f"âœ… ChromaDBè¿æ¥æˆåŠŸï¼Œå½“å‰æ–‡æ¡£æ•°: {count}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_custom_embeddings() 